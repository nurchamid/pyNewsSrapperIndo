{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'ID')\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import html\n",
    "import json\n",
    "import time\n",
    "from requests.exceptions import ConnectionError, TooManyRedirects\n",
    "import unicodedata\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = mysql.connector.connect(user='root', password='', host='127.0.0.1', database='news_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Script Contain in Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw = pd.read_sql(\"select id, url, source from article where source='otosia' and content like '%getelementsbytagname%'\", con)\n",
    "# for index, row in raw.iterrows():\n",
    "#     print(row['url'])\n",
    "#     response = requests.get(row['url'])\n",
    "#     html = response.text\n",
    "#     soup = BeautifulSoup(html, \"html5lib\")\n",
    "    \n",
    "#     article = soup.find('div', class_=\"OtoDetailNews\")\n",
    "    \n",
    "#     for div in article.findAll('div', class_='relatedContentBox'):\n",
    "#         div.decompose()\n",
    "\n",
    "#     for tabel in article.findAll('table'):\n",
    "#         tabel.decompose()\n",
    "\n",
    "#     for script in article.findAll('script'):\n",
    "#         script.decompose()\n",
    "        \n",
    "#     detail = BeautifulSoup(article.decode_contents().replace('<br/>', ' '), \"html5lib\")\n",
    "#     content = re.sub(r'\\n|\\t|\\b|\\r','',unicodedata.normalize(\"NFKD\",detail.get_text(strip=True)))\n",
    "#     content = content.replace(\"‘\",\"\").replace(\"‘\",\"\").replace(\"'\",\"\")\n",
    "                \n",
    "#     cursor = con.cursor()\n",
    "#     sql = \"UPDATE article SET content = '\"+content+\"' WHERE id = \"+str(row['id'])\n",
    "#     cursor.execute(sql)\n",
    "#     con.commit()\n",
    "#     cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = pd.read_sql(\"select id, url, source from article where source='otosia' and author like '%reporter%'\", con)\n",
    "# for index, row in raw.iterrows():\n",
    "#     print(row['url'])\n",
    "#     response = requests.get(row['url'])\n",
    "#     html = response.text\n",
    "#     soup = BeautifulSoup(html, \"html5lib\")\n",
    "    \n",
    "#     try:\n",
    "#         author = soup.findAll('span', class_=\"newsdetail-schedule\")[1].get_text(strip=True)\n",
    "#         author = author.split(' | ')[0].replace(\"Editor : \", \"\")\n",
    "#     except(Exception):\n",
    "#         author = soup.find('span', class_='reporter').get_text(strip=True)\n",
    "#         author = author.split(' | ')[0].replace(\"Editor :\", \"\")\n",
    "                \n",
    "#     cursor = con.cursor()\n",
    "#     sql = \"UPDATE article SET author = '\"+author+\"' WHERE id = \"+str(row['id'])\n",
    "#     cursor.execute(sql)\n",
    "#     con.commit()\n",
    "#     cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.otosia.com/berita/4-model-ini-bisa-jawab-rasa-penasaranmu-tentang-motor-kawasaki.html\n"
     ]
    }
   ],
   "source": [
    "raw = pd.read_sql(\"select id, url, source from article where source='otosia' and url='https://www.otosia.com/berita/4-model-ini-bisa-jawab-rasa-penasaranmu-tentang-motor-kawasaki.html'\", con)\n",
    "for index, row in raw.iterrows():\n",
    "    print(row['url'])\n",
    "    response = requests.get(row['url'])\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, \"html5lib\")\n",
    "\n",
    "    try:\n",
    "        author = soup.findAll('span', class_=\"newsdetail-schedule\")[1].get_text(strip=True)\n",
    "        author = author.split(' | ')[0].replace(\"Editor : \", \"\")\n",
    "    except(Exception):\n",
    "        author = soup.find('span', class_='reporter').get_text(strip=True)\n",
    "        author = author.split(' | ')[0].replace(\"Editor :\", \"\")\n",
    "\n",
    "    cursor = con.cursor()\n",
    "    sql = \"UPDATE article SET author = '\"+author+\"' WHERE id = \"+str(row['id'])\n",
    "    cursor.execute(sql)\n",
    "    con.commit()\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.otosia.com/berita/4-model-ini-bisa-jawab-rasa-penasaranmu-tentang-motor-kawasaki.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
